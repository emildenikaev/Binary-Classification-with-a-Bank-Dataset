**Курс: Auto ML - Практическое задание**  
**Соревнование: [Kaggle Playground Series S5E8](https://www.kaggle.com/competitions/playground-series-s5e8)**  

## Цель проекта  
Разработать и реализовать решение для задачи бинарной классификации - предсказание того, оформит ли клиент срочный депозит в банке на основе демографических и финансовых признаков.  

Основные задачи:
- Провести качественный EDA
- Превзойти бейзлайн на LightAutoML (LAMA)
- Реализовать воспроизводимый, чистый и структурированный код
- Применить современные методы препроцессинга, feature engineering и ансамблирования

## Основные результаты

| Модель                            | OOF ROC-AUC | PR-AUC  | 
|----------------------------------|-------------|---------|
| LightAutoML (Fast)               | 0.95433     | 0.75843 |
| LightAutoML (Medium)             | 0.96340     | 0.79092 |
| LightGBM + Optuna + FE       | 0.96930 | 0.81652 |
| CatBoost                         | 0.96642     | 0.79580 |
| Ensemble (0.6 LGBM + 0.4 CatBoost)| 0.96894     | 0.81549 |

 **Результат на Kaggle: `0.96995`** — **превосходит оба LAMA-бейзлайна**, что подтверждает успешность выбранного подхода. К сожалению для получения оценки не удалось загрузить решение и пошарить его на всех - нужно добавлять в коллабораторы или подтвердить личность, а СМС не приходят (но к счастью мой аккаунт уже был подтвержден достаточно для загрузки файла `final_submission.csv` и получения приватного скора)

## Основные этапы работы

### 1. **Анализ целевой переменной (y)**
- Целевая переменная бинарная (`0` – не оформил депозит, `1` – оформил)
- Распределение **сильно несбалансированное**: ~8.8% положительных случаев
- Выбрана метрика **ROC-AUC** как устойчивая к дисбалансу

### 2. **EDA и анализ признаков**
- **Пропусков нет** — данные чистые
- **Числовые признаки**: `age`, `balance`, `duration`, `campaign`, `pdays`, `previous`
- **Категориальные признаки**: `job`, `marital`, `education`, `default`, `housing`, `loan`, `contact`, `month`, `poutcome`
- **Key observations**:
  - `balance` имеет сильный правый хвост 
  - `age` слегка смещён 
  - Низкая корреляция между числовыми признаками → малый риск мультиколлинеарности

### 3. **Feature Engineering**
Созданы новые признаки:
- `balance_pos`: бинарный признак — положительный баланс или нет
- `age_bin`: возрастные группы (0–30, 30–40, ..., 60+)
- `housing_and_loan`: комбинированный признак взаимодействия (`housing_loan`)

### 4. **Кодирование категориальных признаков**
- Реализованы кастомные `sklearn`-совместимые трансформеры:
  - **TargetEncoderSmoothing** - сглаженное target-кодирование для защиты от переобучения
  - **FrequencyEncoder** - замена категорий на их частоту в train

### 5. **Моделирование**
Реализовано **5 подходов**:
1. **LightAutoML (Fast)** — только LightGBM, 10 мин
2. **LightAutoML (Medium)** — LGBM + CatBoost + RF, 60 мин
3. **LightGBM + Optuna** — гиперпараметрическая оптимизация (20 trials), Stratified CV
4. **CatBoost** — работает с категориальными признаками без явного кодирования, использует ordered boosting для защиты от утечки, и встроенный баланс классов
5. **Ensemble** — взвешенное среднее (0.6 LGBM + 0.4 CatBoost)

Использован **Stratified K-Fold (k=5)** для корректной оценки и предотвращения утечки данных.

### 6. **Оценка и визуализация качества**
- **Калибровочные кривые** — модели слегка переоценивают вероятности (характерно для tree-based)
- **Precision-Recall** — LightGBM лидирует и по PR-AUC, что важно при дисбалансе
- **Распределение предсказаний** — все модели дают разумные вероятности

## Архитектура кода
- self-contained pipeline на базе `sklearn.Pipeline`
- Все препроцессинг-шаги инкапсулированы в классы (`BaseEstimator`, `TransformerMixin`)
- Соблюдены принципы SOLID и PEP 8
- Реализовано логгирование экспериментов:
  - Сохранение OOF/тестовых предсказаний (`*.pkl`)
  - JSON-файл с метаданными (`experiment_results.json`)
  - CSV-файл для отправки (`final_submission.csv`)


## Технологический стек
- Python 3.10+
- `pandas`, `numpy`, `scikit-learn`
- `LightAutoML`, `CatBoost`, `LightGBM`
- `Optuna`
- `seaborn`, `matplotlib`
- `joblib`, `json`

---

## Выводы
- **Цель достигнута**: кастомное решение (`LightGBM + FE + Optuna`) превзошло LAMA-бейзлайн (0.96930 vs 0.96340 OOF AUC)
- **Качественный EDA** позволил сформулировать обоснованные гипотезы и создать информативные признаки
- **Использование pipeline и классов** обеспечило чистоту и воспроизводимость кода
- **Ансамблирование** дало стабильность, но лучший одиночный результат показала модель LightGBM
- **Kaggle Score**: `0.96995`  
